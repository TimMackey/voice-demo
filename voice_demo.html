<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Voice to Assistant</title>
    <script crossorigin="anonymous" src="https://kit.fontawesome.com/14e0b589b4.js">
    </script>
    <style>
            body {
                font-family: Arial, sans-serif;
                padding: 2rem;
            }

            .label {
                margin-top: 1.5rem;
                font-weight: bold;
            }

            .input-row {
                display: flex;
                align-items: stretch; /* ensures both children match height */
                gap: 0.4rem;
                margin-top: 1rem;
            }

            #micIndicator {
                display: flex;
                align-items: center;
                justify-content: center;
                background-color: white;
                cursor: pointer;
                padding: 0;
                color: blue;
            }

            .mic-icon {
                color: #3149d0;
            }

            .visible .mic-icon {
                animation: none;
            }

            .prompt .mic-icon {
                animation: flash 1s infinite;
            }

            .stop .mic-icon {
                /* display: none; */
                color: red;
            }

            @keyframes flash {
                0%,
                100% {
                    opacity: 1;
                }
                50% {
                    opacity: 0;
                }
            }

            textarea {
                font-size: 1em;
                line-height: 1.5em;
                height: 1.5em;
                padding: 0.2em 0.4em;
                resize: none;
                overflow: hidden;
                border: 1px solid #ccc;
                flex: 1;
            }

            .flash-placeholder {
                color: #3149d0;
                font-weight: bold;
                /* animation: flash-color 1.2s infinite; */
            }

            #modalOverlay {
                position: fixed;
                top: 0;
                left: 0;
                width: 100vw;
                height: 100vh;
                display: none;
                z-index: 1000;
            }

            .modal-backdrop {
                background-color: rgba(0, 0, 0, 0.25);
                width: 100%;
                height: 100%;
                /* backdrop-filter: blur(2px); */
            }

            .modal-spinner {
                position: absolute;
                top: 50%;
                left: 50%;
                transform: translate(-50%, -50%);
                color: #3149d0;
            }

            .spinner {
                animation: spin 1s linear infinite;
            }

            @keyframes spin {
                0% { transform: rotate(0deg); }
                100% { transform: rotate(360deg); }
            }
        </style>
</head>
<body>

    <!-- Modal Overlay with Spinner -->
    <div id="modalOverlay" style="display: none;">
        <div class="modal-backdrop"></div>
        <div class="modal-spinner">
            <i class="fa-solid fa-spinner fa-2xl spinner"></i>
        </div>
    </div>
    <!-- Modal Content -->

    <div class="label">GradeScan AI Assistant</div>
    <div class="input-row">
        <span id="micIndicator" title="Click me">
            <i class="fa-solid fa-circle-microphone fa-xl mic-icon"></i>
        </span>
        <textarea id="userMessage"
                  rows="1"
                  style="line-height: 1.5em; overflow: hidden; resize: none">
        </textarea>
    </div>

    <div class="label">Assistant Response:</div>
    <div id="assistantReplyBox"
         style="height: 400px; overflow-y: auto; border: 1px solid #ccc; padding: 10px; margin-top: 10px; overscroll-behavior-y: contain; resize: vertical;">
    </div>

    <script>
            // Setup speech recognition API
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                alert("Speech recognition not supported in this browser.");
                throw new Error("SpeechRecognition not available");
            }

            // API endpoint for assistant
            const apiUrl =
            "https://gradescan-server.azurewebsites.net/api/ttmAiAssistant/chat";
            // "https://localhost:44301/api/ttmAiAssistant/chat?source=localhost";

            // UI state constants
            const STATE = {
                VISIBLE: "visible",
                STOP: "stop",
                PROMPT: "prompt"
            };

            function getSeconds() {
                const now = new Date();
                const second = now.getSeconds();
                const millis = now.getMilliseconds();
                // const hour = now.getHours();
                // const minute = now.getMinutes();
                // console.log(`Current time: ${hour}:${minute}:${second}.${millis}`);
                let secs = second + "." + millis;
                return secs;
            }

            function getTrueCallerLineNumber(skipFrames = 2) {
                const stack = new Error().stack.split("\n");
                for (let i = skipFrames; i < stack.length; i++) {
                    const match = stack[i].match(/:(\d+):\d+\)?$/);
                    if (match) return match[1]; // Line number
                }
                return "unknown";
            }

            // Wrapper to track recognition status
            const recognition = {
                _recognitionStarted: false,

                get started() {
                    const line = getTrueCallerLineNumber(3); // skip 3 levels
                    // console.log(`get ${this._recognitionStarted} = recognition.started [line ${line}]`, getSeconds());
                    return this._recognitionStarted;
                },

                set started(value) {
                    const line = getTrueCallerLineNumber(3); // skip 3 levels
                    this._recognitionStarted = value;
                    // console.log(`set recognition.started = ${value} [line ${line}]`, getSeconds());
                }
            };

            // Speech recognition setup
            const speechRecognition = new SpeechRecognition();
            speechRecognition.continuous = false;
            speechRecognition.interimResults = false;
            speechRecognition.lang = "en-US";

            // UI elements
            const userMessageBox = document.getElementById("userMessage");
            const assistantReplyBox = document.getElementById("assistantReplyBox");
            const micIndicator = document.getElementById("micIndicator");

            // State flags
            let suppressRecognitionRestart = false;
            let suppressMicIndicatorUpdate = false;
            let resumeAfterSpeak = false;
            let manuallyStopped = false;
            let listening = false;
            let speaking = false;

            // Debug helper to get line number
            function getLineNumber() {
                const err = new Error();
                const stackLines = err.stack.split("\n");
                // The line of interest is usually the third line in the stack trace
                // Format example (Chrome): at Object.<anonymous> (<anonymous>:6:9)
                const callerLine = stackLines[2] || stackLines[1];
                const match = callerLine.match(/:(\d+):\d+\)?$/);
                return match ? parseInt(match[1], 10) : null;
            }

            // Show initial placeholder
            showFlashingPlaceholder("Click the microphone then voice your question.");
            updateMicIndicator(STATE.PROMPT, "init", getLineNumber());

            // Mic indicator control
            function updateMicIndicator(state, func = "unknown", line = 0) {
                if (state === null || state === undefined) {
                    console.warn("updateMicIndicator(state = undefined, func =", func, ", line =", line, ")");
                    return;
                }
                micIndicator.className = state;
                switch (state) {
                    case STATE.VISIBLE:
                        document.getElementById("micIndicator").title = "Click to de-activate mic";
                        break;
                    case STATE.STOP:
                        document.getElementById("micIndicator").title = "Click to stop speaking";
                        break;
                    case STATE.PROMPT:
                        document.getElementById("micIndicator").title = "Click to activate mic";
                        break;
                }
                // console.log("updateMicIndicator(", state, func, line, ")", getSeconds());
            }

            // Placeholder helpers
            function showFlashingPlaceholder(text) {
                userMessageBox.value = text;
                userMessageBox.classList.add("flash-placeholder");
                // userMessageBox.readOnly = true;
            }

            function setAskMePlaceholder() {
                userMessageBox.value = "Type or ask me a question.  I'm listening...";
                userMessageBox.classList.remove("flash-placeholder");
                // userMessageBox.readOnly = true;
            }

            function setAskMeAnotherQuestionPlaceholder() {
                userMessageBox.value = "Type or ask me another question.  I'm listening...";
                userMessageBox.classList.remove("flash-placeholder");
                // userMessageBox.readOnly = true;
            }

            function clearPlaceholder() {
                userMessageBox.value = "";
                userMessageBox.classList.remove("flash-placeholder");
                // userMessageBox.readOnly = false;
            }

            // Speech recognition event bindings
            speechRecognition.onstart = () => {
                if (!suppressMicIndicatorUpdate && !recognition.started) {
                    updateMicIndicator(STATE.VISIBLE, "recognition.onstart", getLineNumber());
                }
                recognition.started = true;
            };

            speechRecognition.onend = () => {
                recognition.started = false;

                if (!manuallyStopped && !speaking && !suppressRecognitionRestart) {
                    listening = true;
                    setTimeout(() => {
                    if (!recognition.started && !manuallyStopped) {
                            try {
                                suppressMicIndicatorUpdate = true;
                                speechRecognition.start();
                            } catch (err) {
                                console.warn("catch recognition.onend Recognition restart failed:", err.message);
                            }
                        }
                    }, 1000);
                } else {
                    if (!suppressMicIndicatorUpdate) {
                        updateMicIndicator(STATE.STOP, "recognition.onend", getTrueCallerLineNumber(3));
                    }
                }
            };

            speechRecognition.onerror = (event) => {
                if (manuallyStopped || speaking) {
                    // console.log("recognition.onerror Ignored error due to manual stop or speech:", event.error);
                    return;
                }

                switch (event.error) {
                    case "no-speech":
                    case "audio-capture":
                    case "aborted":
                        setTimeout(() => {
                            if (!manuallyStopped && !recognition.started) {
                                try {
                                    speechRecognition.start();
                                    recognition.started = true;
                                } catch (err) {
                                    console.warn("catch recognition.onerror recognition.start() failed:", err.message);
                                }
                            }
                        }, 300);
                        break;

                    case "not-allowed":
                    case "service-not-allowed":
                        manuallyStopped = true;
                        break;

                    default:
                        console.warn(`Unhandled speech recognition error: ${event.error}`, true);
                        break;
                }
            };

            speechRecognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript.trim();
                if (speaking) {
                    // console.log("recognition.onresult  Assistant is still speaking...");
                    return;
                }
                userMessageBox.value = transcript;
                sendMessage(transcript);
            };

            // Mic click handler
            micIndicator.addEventListener("click", () => {
                if (!listening) {
                    clearPlaceholder();
                    setAskMePlaceholder();

                    manuallyStopped = false;
                    speaking = false;
                    listening = true;
                    assistantReplyBox.innerHTML = "";
                    updateMicIndicator(STATE.VISIBLE, "micIndicator.addEventListener", getLineNumber());

                    if (!recognition.started) {
                        speechRecognition.start();
                        recognition.started = true;
                    }
                } else {
                    manuallyStopped = true;
                    speechRecognition.stop();
                    window.speechSynthesis.cancel();
                    recognition.started = false;
                    listening = false;
                    updateMicIndicator(STATE.STOP, "micIndicator.addEventListener", getLineNumber());
                }
            });

            // Resume listening after speaking ends
            function resumeListening() {
                listening = true;
                resumeAfterSpeak = false;
                suppressRecognitionRestart = false;

                const line = getTrueCallerLineNumber(3);

                if (!recognition.started) {
                    try {
                        suppressMicIndicatorUpdate = false;
                        recognition.started = true;
                        speechRecognition.start(); // safe start
                        suppressRecognitionRestart = false;
                        updateMicIndicator(STATE.VISIBLE, "resumeListening", line);
                        setAskMeAnotherQuestionPlaceholder();
                    } catch (err) {
                        console.warn("resumeListening: recognition.start() failed:", err.message);
                    }
                }
            }

            // Send the message and handle response
            function sendMessage(userMessage) {
                if (!userMessage.trim()) return;

                // Stop mic and prepare for fetch
                suppressMicIndicatorUpdate = true;
                speechRecognition.stop(); // Stop browser mic immediately
                suppressRecognitionRestart = true;
                recognition.started = false;
                updateMicIndicator(STATE.STOP, "sendMessage fetch", getTrueCallerLineNumber(3));

                // Enable modal overlay
                const modalOverlay = document.getElementById("modalOverlay");
                if (modalOverlay) {
                    modalOverlay.style.display = "block";
                }

                fetch(apiUrl, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    credentials: "include",
                    body: JSON.stringify({ UserMessage: userMessage, Source: "Voice Demo" })
                })
                    .then(async (res) => {
                        if (!res.ok) {
                            const errorData = await res.json();
                            throw new Error(errorData.result.plainText || "API error");
                        }
                        return res.json();
                    })
                    .then((response) => {
                        const html = JSON.parse(response.result.result).choices[0].message.content.trim();
                        assistantReplyBox.innerHTML = html;
                        updateMicIndicator(STATE.STOP, "sendMessage response", getLineNumber());

                        assistantReplyBox.querySelectorAll("a").forEach((a) => {
                            a.setAttribute("target", "_blank");
                            a.setAttribute("rel", "noopener noreferrer");
                        });

                        const utterance = new SpeechSynthesisUtterance(response.result.plainText);
                        speaking = true;
                        resumeAfterSpeak = true;
                        window.speechSynthesis.speak(utterance);

                        utterance.onend = utterance.onerror = () => {
                            speaking = false;
                            resumeAfterSpeak = false;
                            resumeListening(); // Always resume mic
                        };
                    })
                    .catch((error) => {
                        console.error("catch sendMessage API Error:", error.message || error);
                        assistantReplyBox.innerHTML = error.message || error;
                    })
                    .finally(() => {
                        // Always disable modal overlay at the end
                        if (modalOverlay) {
                            modalOverlay.style.display = "none";
                        }
                    });
            }

            // Clear textarea and stop mic when user clicks inside
            userMessageBox.addEventListener("focus", () => {
                // if (recognition.started) {
                    manuallyStopped = true;
                    suppressRecognitionRestart = true;
                    speechRecognition.stop();
                    recognition.started = false;
                    listening = false;
                    updateMicIndicator(STATE.STOP, "focus", getLineNumber());
                // }
                userMessageBox.value = "";
                userMessageBox.classList.remove("flash-placeholder");
                userMessageBox.readOnly = false;
            });

            // Send message on Enter and resume mic after response
            userMessageBox.addEventListener("keydown", (e) => {
                if (e.key === "Enter" && !e.shiftKey) {
                    e.preventDefault(); // Prevent default newline behavior
                    const text = userMessageBox.value.trim();
                    if (text.length > 0) {
                        userMessageBox.blur();
                        sendMessage(text);
                    }
                }
            });

            // Show initial state
            showFlashingPlaceholder("Click the microphone then speak your question.  Or type your question here.");
            updateMicIndicator(STATE.PROMPT, "init", getLineNumber());
        </script>
    </body>
</html>
