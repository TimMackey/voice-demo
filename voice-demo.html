<!DOCTYPE html>
<html lang="en">
    <head>
        <script crossorigin="anonymous" src="https://kit.fontawesome.com/c0a21d601f.js"></script>
        <meta charset="UTF-8" />
        <title>Voice to Assistant</title>

        <style>
            body {
                font-family: Arial, sans-serif;
                padding: 2rem;
            }

            textarea {
                width: 100%;
                height: 80px;
                margin-top: 1rem;
            }

            button {
                margin-top: 1rem;
                padding: 10px 20px;
                font-size: 16px;
            }

            .label {
                margin-top: 1.5rem;
                font-weight: bold;
            }

            .normal-status {
                padding-top: 10px;
                color: blue;
                font-weight: bold;
                display: none;
            }

            .flashing-status {
                padding-top: 10px;
                color: red;
                font-weight: bold;
                display: none;
                animation: flash 2s infinite;
            }

            .controls-row {
                display: flex;
                align-items: center;
                gap: 0.5rem; /* optional spacing between items */
            }

            #micIndicator {
                font-size: 24px;
                z-index: 1000;
                display: inline; /* Always visible */
            }

            .mic-icon {
                cursor: pointer;
            }

            .mic-icon {
                cursor: pointer;
            }

            .mic-on .mic-icon {
                color: #3149d0;
                animation: flash 1s infinite;
                width: 50px;
            }

            .mic-off .mic-icon {
                color: black;
                animation: none;
                width: 50px;
            }

            @keyframes flash {
                0%,
                100% {
                    opacity: 1;
                }
                50% {
                    opacity: 0;
                }
            }

            /* #userMessage::placeholder {
                color: #3149d0;
                font-weight: bold;
                animation: flash-blue 1.5s infinite;
            } */

            .flash-placeholder {
                color: #3149d0;
                font-weight: bold;
                animation: flash-color 1.2s infinite;
            }

            @keyframes flash-color {
                0%,
                100% {
                    color: #3149d0;
                }
                50% {
                    color: transparent;
                }
            }
        </style>
    </head>

    <body>
        <div class="label">GradeScan AI Assistant</div>

        <div class="controls-row">
            <span id="micIndicator" title="Toggle microphone">
                <i id="micIcon" class="fas fa-microphone-slash"></i>
            </span>
            <button id="stopSpeakingBtn">ðŸ›‘ Stop Speaking</button>
        </div>

        <textarea
            id="userMessage"
            rows="1"
            style="height: 1.5em; line-height: 1.5em; overflow: hidden; resize: none"
        ></textarea>

        <div class="normal-status" id="statusMessage">Click Start Listening to begin...</div>

        <div class="label">Assistant Response:</div>
        <div
            id="assistantReplyBox"
            style="
                height: 400px;
                overflow-y: auto;
                border: 1px solid #ccc;
                padding: 10px;
                margin-top: 10px;
                overscroll-behavior-y: contain;
                resize: vertical;
            "
        ></div>

        <script>
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

            if (!SpeechRecognition) {
                alert("Speech recognition not supported in this browser.");
                throw new Error("SpeechRecognition not available");
            }

            const recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = "en-US";

            const userMessageBox = document.getElementById("userMessage");
            const assistantReplyBox = document.getElementById("assistantReplyBox");
            const stopSpeakingBtn = document.getElementById("stopSpeakingBtn");
            const statusMessageDiv = document.getElementById("statusMessage");
            const micIndicator = document.getElementById("micIndicator");
            const userMessage = document.getElementById("userMessage");

            let recognitionStarted = false;
            let manuallyStopped = false;
            let listening = false;
            let speaking = false;
            let heard = false;
            let source = "Voice Demo";

            updateStatus("Click Start Listening to begin", false);

            function clearPlaceholder() {
                userMessage.value = "";
                userMessage.classList.remove("flash-placeholder");
                userMessage.style.fontWeight = "normal";
                userMessage.style.color = "black";
                userMessage.readOnly = false;
            }

            function showFlashingPlaceholder(text) {
                userMessage.value = text;
                userMessage.classList.add("flash-placeholder");
                userMessage.readOnly = true;
            }

            function clearPlaceholder() {
                userMessage.value = "";
                userMessage.classList.remove("flash-placeholder");
                userMessage.readOnly = false;
            }

            function updateStatus(msg, flash = false, hidden = false) {
                statusMessageDiv.textContent = msg;
                statusMessageDiv.className = flash ? "flashing-status" : "normal-status";
                statusMessageDiv.style.display = hidden ? "none" : "block";
            }

            function updateMicIndicator(on = true) {
                micIndicator.className = on ? "mic-on" : "mic-off";
                const micIcon = document.getElementById("micIcon");
                micIcon.setAttribute(
                    "class",
                    on ? "fas fa-microphone mic-icon" : "fas fa-microphone-slash mic-icon"
                );
            }

            function hideMicIndicator() {
                micIndicator.style.display = "none";
            }

            console.log = function (...args) {
                const msg = args.join(" ");
                updateStatus(msg);
                window.console.info(...args);
            };

            console.error = function (...args) {
                const msg = args.join(" ");
                updateStatus("âŒ " + msg, true);
                window.console.warn(...args);
            };

            recognition.onresult = (event) => {
                console.log("recognition.onresult");
                // if (heard || speaking) return;

                const transcript = event.results[0][0].transcript.trim();
                console.log("Heard: " + transcript);

                // if (transcript === "stop") {
                //     console.log("Heard 'stop'");
                //     manuallyStopped = true;
                //     window.speechSynthesis.cancel();
                //     recognition.stop();
                //     updateMicIndicator(false);
                //     updateStatus(
                //         "ðŸ›‘ Audio and listening stopped. Click Start Listening to resume.",
                //         false
                //     );
                //     return;
                // }
                if (speaking) {
                    console.log("Assistant is still speaking...");
                    return;
                }
                heard = true;
                userMessageBox.value = transcript;

                sendMessage(transcript);
            };

            recognition.onerror = (event) => {
                console.warn(`Speech recognition error: ${event.error}`);

                // Ignore if manually stopped or currently speaking
                if (manuallyStopped || speaking) {
                    console.log("Ignored error due to manual stop or speech:", event.error);
                    return;
                }

                // Handle recoverable errors
                switch (event.error) {
                    case "no-speech":
                    case "audio-capture":
                    case "aborted":
                        setTimeout(() => {
                            // âœ… Only restart if not manually stopped and not already started
                            if (!manuallyStopped && !recognitionStarted) {
                                try {
                                    recognition.start();
                                    recognitionStarted = true;
                                    updateStatus("Listening again...", true);
                                    updateMicIndicator(true);
                                } catch (err) {
                                    console.error("Retry failed:", err.message);
                                }
                            }
                        }, 300);
                        break;

                    case "not-allowed":
                    case "service-not-allowed":
                        updateStatus("Microphone access denied or blocked.", true);
                        manuallyStopped = true;
                        break;

                    default:
                        updateStatus(`Unhandled recognition error: ${event.error}`, true);
                        break;
                }
            };

            recognition.onend = () => {
                recognitionStarted = false;

                if (!manuallyStopped && !speaking) {
                    heard = false;
                    listening = true;

                    // Wait longer to avoid overlapping restart issues
                    setTimeout(() => {
                        if (!recognitionStarted) {
                            try {
                                recognition.start();
                                // .onstart will flip recognitionStarted to true
                                updateStatus("ðŸŽ™ï¸ Listening again...", true);
                            } catch (err) {
                                console.error("Recognition restart failed:", err.message);
                            }
                        }
                    }, 1000); // ðŸ‘ˆ increase delay to avoid race condition
                } else {
                    updateMicIndicator(false);
                }
            };

            recognition.onstart = () => {
                recognitionStarted = true;
                heard = false;
                updateMicIndicator(true);
            };

            micIndicator.addEventListener("click", () => {
                if (!listening) {
                    clearPlaceholder(); // ðŸ‘ˆ Revert to black normal font
                    updateStatus("Listening...", false);

                    manuallyStopped = false;
                    speaking = false;
                    heard = false;
                    listening = true;
                    userMessageBox.value = "";
                    assistantReplyBox.innerHTML = "";
                    updateMicIndicator(true);

                    if (!recognitionStarted) {
                        recognition.start();
                        recognitionStarted = true;
                    }
                } else {
                    manuallyStopped = true;
                    recognition.stop();
                    window.speechSynthesis.cancel();
                    recognitionStarted = false;
                    listening = false;
                    updateMicIndicator(false);

                    updateStatus("ðŸ›‘ Microphone turned off.", false);
                }
            });

            updateStatus("Click the microphone to begin", false);
            updateMicIndicator(false);
            // Initialize placeholder on load
            showFlashingPlaceholder("Click the microphone then start speaking...");

            stopSpeakingBtn.addEventListener("click", () => {
                manuallyStopped = true;
                window.speechSynthesis.cancel();
                recognition.stop();
                recognitionStarted = false;
                updateMicIndicator(false);
                updateStatus(
                    "ðŸ›‘ Audio and listening stopped. Click Start Listening to resume.",
                    false
                );
            });

            function sendMessage(userMessage) {
                if (!userMessage.trim()) return;

                const payload = {
                    UserMessage: userMessage,
                    Source: source,
                };

                const apiUrl = "https://localhost:44301/api/ttmAiAssistant/chat?source=localhost"; // Dev
                //   "https://gradescan-server.azurewebsites.net/api/ttmAiAssistant/chat"; // Live

                recognition.stop();
                recognitionStarted = false;
                updateMicIndicator(false);

                updateStatus("Searching for answer...", true);

                fetch(apiUrl, {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/json",
                    },
                    credentials: "include", // <- REQUIRED to send session cookie
                    body: JSON.stringify({
                        UserMessage: userMessage,
                        Source: source,
                    }),
                })
                    .then(async (res) => {
                        if (!res.ok) {
                            const errorData = await res.json();
                            throw new Error(errorData.result.plainText || "API error");
                        }
                        return res.json();
                    })
                    .then((response) => {
                        updateStatus("Formatting reponse...", false);
                        const jsonResponse = JSON.parse(response.result.result);
                        const html = jsonResponse.choices[0].message.content.trim();
                        assistantReplyBox.innerHTML = html;
                        updateStatus("Speaking.", false);
                        recognition.stop();
                        recognitionStarted = false;
                        updateMicIndicator(false);

                        assistantReplyBox.querySelectorAll("a").forEach((a) => {
                            a.setAttribute("target", "_blank");
                            a.setAttribute("rel", "noopener noreferrer");
                        });

                        const utterance = new SpeechSynthesisUtterance(response.result.plainText);
                        speaking = true;
                        window.speechSynthesis.speak(utterance);
                        updateStatus("Speaking.", false);

                        utterance.onerror = (event) => {
                            updateStatus("Ask me another question.", false);
                            speaking = false;
                            heard = false;
                            listening = true;
                            if (!recognitionStarted) {
                                recognition.start();
                                recognitionStarted = true;
                                updateMicIndicator(true); // <-- Update to mic-on
                            }
                        };

                        utterance.onend = () => {
                            speaking = false;
                            heard = false;
                            listening = true; // <-- Reactivate listening
                            updateStatus("Ask me another question.", false);
                            if (!recognitionStarted) {
                                recognition.start();
                                recognitionStarted = true;
                                updateMicIndicator(true); // <-- Update to mic-on (flashing blue)
                            }
                        };
                    })
                    .catch((error) => {
                        console.error("API Error:", error.message || error);
                        assistantReplyBox.innerHTML = error.message || error;
                    });
            }
        </script>
    </body>
</html>
